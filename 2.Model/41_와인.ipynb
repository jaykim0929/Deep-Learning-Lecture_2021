{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "41_와인.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqIgDOIgRe4J"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQPBKh-lr34y"
      },
      "source": [
        "seed = 2021\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "yChTPc3EaDDp",
        "outputId": "4745d696-a10b-4906-bb9e-8dd8d9fc56a7"
      },
      "source": [
        "import pandas as pd\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "filename = list(uploaded.keys())[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-44005a5e-eedc-4eaf-af7b-067a55389259\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-44005a5e-eedc-4eaf-af7b-067a55389259\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wine.csv to wine (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "BAq5rQvTaDP_",
        "outputId": "8e982086-b17b-439f-e083-801052f5cc1e"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0     1     2    3      4     5     6       7     8     9    10  11  12\n",
              "0  7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
              "1  7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
              "2  7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIt88QWCaDSx",
        "outputId": "d4835c00-73d9-4ea0-cbe2-5bf076a3bfcf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    df.iloc[:, :-1].values, df.iloc[:, -1], stratify=df.iloc[:, -1].values, random_state=seed\r\n",
        ")\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4872, 12), (1625, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uyyELEcbFWr"
      },
      "source": [
        "### 모델 정의/설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ConF4yTQaDVS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLpQSF-FaDXx",
        "outputId": "63181f78-a17d-4cfc-bfc0-0c8ca3a06d12"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\r\n",
        "model.add(Dense(12, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 30)                390       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 12)                372       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTghI65CaDaT"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMAFvBIirJXW"
      },
      "source": [
        "### 모델 저장 관련 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVUlyYauaDcx"
      },
      "source": [
        "import os\r\n",
        "MODEL_DIR = './model/'\r\n",
        "if not os.path.exists(MODEL_DIR):\r\n",
        "    os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZeU1j9Zc4Pt",
        "outputId": "6d11ef7c-7d79-4270-bfce-93f1d5a3183c"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 720\n",
            "drwxr-xr-x 2 root root   4096 Feb 10 00:59  model\n",
            "drwxr-xr-x 1 root root   4096 Feb  4 15:26  sample_data\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 02:06 'wine (1).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 00:47  wine.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFSkp6VSc5ne"
      },
      "source": [
        "# 모델 저장조건 설정\r\n",
        "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGaCvJjCdRGG"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \r\n",
        "                               verbose=1, save_best_only=True)\r\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0YIcS8XsWMB"
      },
      "source": [
        "### 모델 학습 및 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VPsOURBeK43",
        "outputId": "011591df-bbbb-4959-9fa1-f996f01e7e1d"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=500, batch_size=200,\r\n",
        "                    verbose=0, callbacks=[checkpointer, early_stopping])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.41822, saving model to ./model/best001-0.4182.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.41822 to 0.28623, saving model to ./model/best002-0.2862.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.28623 to 0.24628, saving model to ./model/best003-0.2463.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24628 to 0.22050, saving model to ./model/best004-0.2205.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.22050 to 0.20001, saving model to ./model/best005-0.2000.hdf5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.20001 to 0.19209, saving model to ./model/best006-0.1921.hdf5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.19209 to 0.18488, saving model to ./model/best007-0.1849.hdf5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.18488 to 0.18360, saving model to ./model/best008-0.1836.hdf5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.18360 to 0.17670, saving model to ./model/best009-0.1767.hdf5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.17670 to 0.17541, saving model to ./model/best010-0.1754.hdf5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.17541 to 0.17388, saving model to ./model/best011-0.1739.hdf5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.17388 to 0.16688, saving model to ./model/best012-0.1669.hdf5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.16688 to 0.16274, saving model to ./model/best013-0.1627.hdf5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16274 to 0.16253, saving model to ./model/best014-0.1625.hdf5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.16253 to 0.15751, saving model to ./model/best015-0.1575.hdf5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.15751 to 0.15722, saving model to ./model/best016-0.1572.hdf5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.15722 to 0.15508, saving model to ./model/best017-0.1551.hdf5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.15508 to 0.15077, saving model to ./model/best018-0.1508.hdf5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15077 to 0.14924, saving model to ./model/best019-0.1492.hdf5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.14924 to 0.14708, saving model to ./model/best020-0.1471.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.14708 to 0.14639, saving model to ./model/best021-0.1464.hdf5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.14639\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.14639 to 0.13917, saving model to ./model/best023-0.1392.hdf5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.13917 to 0.13772, saving model to ./model/best024-0.1377.hdf5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.13772 to 0.13441, saving model to ./model/best025-0.1344.hdf5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.13441 to 0.12824, saving model to ./model/best026-0.1282.hdf5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.12824 to 0.12421, saving model to ./model/best027-0.1242.hdf5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.12421 to 0.11388, saving model to ./model/best031-0.1139.hdf5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.11388 to 0.10927, saving model to ./model/best032-0.1093.hdf5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.10927 to 0.10697, saving model to ./model/best033-0.1070.hdf5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.10697 to 0.10434, saving model to ./model/best034-0.1043.hdf5\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.10434 to 0.10397, saving model to ./model/best037-0.1040.hdf5\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.10397 to 0.10336, saving model to ./model/best038-0.1034.hdf5\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.10336 to 0.09690, saving model to ./model/best041-0.0969.hdf5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.09690 to 0.09461, saving model to ./model/best044-0.0946.hdf5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.09461\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.09461 to 0.09151, saving model to ./model/best046-0.0915.hdf5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.09151\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.09151 to 0.09145, saving model to ./model/best048-0.0914.hdf5\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.09145 to 0.08915, saving model to ./model/best049-0.0891.hdf5\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.08915 to 0.08568, saving model to ./model/best052-0.0857.hdf5\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.08568 to 0.08503, saving model to ./model/best053-0.0850.hdf5\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.08503 to 0.08463, saving model to ./model/best054-0.0846.hdf5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.08463\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.08463 to 0.08397, saving model to ./model/best056-0.0840.hdf5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.08397\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.08397 to 0.08135, saving model to ./model/best058-0.0813.hdf5\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.08135 to 0.07926, saving model to ./model/best059-0.0793.hdf5\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.07926 to 0.07745, saving model to ./model/best062-0.0774.hdf5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.07745 to 0.07615, saving model to ./model/best065-0.0761.hdf5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.07615 to 0.07327, saving model to ./model/best069-0.0733.hdf5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.07327 to 0.07200, saving model to ./model/best072-0.0720.hdf5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.07200\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.07200 to 0.07014, saving model to ./model/best074-0.0701.hdf5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.07014\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.07014 to 0.06874, saving model to ./model/best076-0.0687.hdf5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.06874 to 0.06720, saving model to ./model/best081-0.0672.hdf5\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.06720\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.06720 to 0.06626, saving model to ./model/best083-0.0663.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.06626\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.06626 to 0.06570, saving model to ./model/best085-0.0657.hdf5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.06570 to 0.06368, saving model to ./model/best089-0.0637.hdf5\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.06368 to 0.06190, saving model to ./model/best098-0.0619.hdf5\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.06190 to 0.06155, saving model to ./model/best101-0.0615.hdf5\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.06155 to 0.06092, saving model to ./model/best105-0.0609.hdf5\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.06092 to 0.05978, saving model to ./model/best109-0.0598.hdf5\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.05978 to 0.05942, saving model to ./model/best110-0.0594.hdf5\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.05942 to 0.05878, saving model to ./model/best121-0.0588.hdf5\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.05878 to 0.05850, saving model to ./model/best122-0.0585.hdf5\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.05850\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.05850 to 0.05746, saving model to ./model/best124-0.0575.hdf5\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.05746 to 0.05745, saving model to ./model/best129-0.0575.hdf5\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05745\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.05745 to 0.05711, saving model to ./model/best131-0.0571.hdf5\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05711\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05711\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.05711 to 0.05606, saving model to ./model/best134-0.0561.hdf5\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.05606 to 0.05559, saving model to ./model/best139-0.0556.hdf5\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.05559 to 0.05528, saving model to ./model/best156-0.0553.hdf5\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.05528 to 0.05464, saving model to ./model/best166-0.0546.hdf5\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.05464 to 0.05425, saving model to ./model/best179-0.0543.hdf5\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.05425\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.05425 to 0.05305, saving model to ./model/best181-0.0531.hdf5\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.05305 to 0.05303, saving model to ./model/best196-0.0530.hdf5\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00213: val_loss improved from 0.05303 to 0.05217, saving model to ./model/best213-0.0522.hdf5\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.05217\n",
            "\n",
            "Epoch 00215: val_loss improved from 0.05217 to 0.05214, saving model to ./model/best215-0.0521.hdf5\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00220: val_loss improved from 0.05214 to 0.05178, saving model to ./model/best220-0.0518.hdf5\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00240: val_loss improved from 0.05178 to 0.05167, saving model to ./model/best240-0.0517.hdf5\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00246: val_loss improved from 0.05167 to 0.05128, saving model to ./model/best246-0.0513.hdf5\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.05128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhGTk2eVsfak"
      },
      "source": [
        "### 잘못된 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggry-VaIeLDN",
        "outputId": "3151a8df-38af-4f0b-bca3-2184c6f65b60"
      },
      "source": [
        "acc = model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 946us/step - loss: 0.0753 - accuracy: 0.9803\n",
            "Accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIFQdw02tVBF"
      },
      "source": [
        "### 베스트 모델로 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcPIOLPDstLt",
        "outputId": "c1e3a708-40f7-4912-99ff-846f2b5b81f9"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "best_model = load_model('./model/best246-0.0513.hdf5')\r\n",
        "acc = best_model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9778\n",
            "Accuracy: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "753rkSnftaT5"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFisyaFPtY3K"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mHFs17DtY8S",
        "outputId": "c5e88e61-0fc3-4992-ca90-057326816798"
      },
      "source": [
        "type(history.history)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjNJ-WtKtY-8"
      },
      "source": [
        "y_vloss=history.history['val_loss']\r\n",
        "y_acc=history.history['accuracy']\r\n",
        "y_vacc=history.history['val_accuracy']\r\n",
        "y_loss=history.history['loss']"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "2Oi3oBlJtZBN",
        "outputId": "804bf7dc-f0c9-4e3c-88bb-4f88fab31690"
      },
      "source": [
        "x_len = np.arange(len(y_acc))\r\n",
        "plt.figure(figsize=(12,8))\r\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"red\", markersize=2, label='loss')\r\n",
        "plt.plot(x_len, y_vacc, \"o\", c=\"blue\", markersize=2, label='val_accuracy')\r\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"orange\", markersize=2, label='val_loss')\r\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"green\", markersize=2, label='accuracy')\r\n",
        "plt.grid()\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkGQ1L-1tZDd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}