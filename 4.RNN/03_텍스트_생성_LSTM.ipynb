{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_텍스트_생성_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsg3Xika5xMT"
      },
      "source": [
        "# LSTM을 이용한 텍스트 생성\r\n",
        "- '경마장에 있는 말이 뛰고 있다'\r\n",
        "- '그의 말이 법이다'\r\n",
        "- '가는 말이 고와야 오는 말이 곱다'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrGlMqtH5qFe"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaIj2Mv46vWQ"
      },
      "source": [
        "seed= 2021\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SWEaQ5_6_LY"
      },
      "source": [
        "text=\"\"\" 경마장에 있는 말이 뛰고 있다\\n\r\n",
        "그의 말이 법이다\\n \r\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJU1iAzO7TRw"
      },
      "source": [
        "# 단어 집합 생성\r\n",
        "t = Tokenizer()\r\n",
        "t.fit_on_texts([text])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5xQMrKvLeev",
        "outputId": "59ac9d33-fd0d-466e-cf50-0ce00b79f1da"
      },
      "source": [
        "# 단어 집합 크기 설정\r\n",
        "vocab_size = len(t.word_index) + 1\r\n",
        "# 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만,\r\n",
        "# 케라스 원-핫 인코딩에서 배열의 인덱스가 0부터 시작하기 때문에\r\n",
        "# 배열의 크기를 실제 단어 집합의 크기보다 +1로 생성해야함 \r\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjFV9-2g8THw",
        "outputId": "57b6a6f1-82ab-478e-baa5-a561859003ad"
      },
      "source": [
        "sequences = []\r\n",
        "for line in text.split('\\n'):\r\n",
        "    encoded = t.texts_to_sequences([line])[0]\r\n",
        "    for i in range(1, len(encoded)):\r\n",
        "        sequence = encoded[:i+1]\r\n",
        "        sequences.append(sequence)\r\n",
        "\r\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcPzbmneAlJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc89619-890a-4f04-b215-41511530299e"
      },
      "source": [
        "# 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\r\n",
        "max_len = max(len(s) for s in sequences) \r\n",
        "print('샘플의 최대 길이 :', max_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhldCCu3BXU_"
      },
      "source": [
        "# 전체 샘플의 길이를 6(가장 긴 샘플의 길이)으로 패딩\r\n",
        "# 'pre' 옵션을 주면 앞을 0으로 패딩\r\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggh7kTk2MFX4"
      },
      "source": [
        "# 각 샘플의 마지막 단어를 레이블로 분리\r\n",
        "X = sequences[:,:-1]\r\n",
        "y = sequences[:,-1]\r\n",
        "# 리스트의 마지막 값을 제외하고 저장한 것은 X\r\n",
        "# 리스트의 마지막 값만 저장한 것은 y. 이는 레이블에 해당됨."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEV09jj_BXSa"
      },
      "source": [
        "# 레이블 데이터 y에 대해서 원-핫 인코딩을 수행\r\n",
        "Y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3WcXJ2kBz_D"
      },
      "source": [
        "### 모델 정의\r\n",
        "- Embedding\r\n",
        "- LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_xtLE88BXJh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXy1rpwVBXG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eac66b8-376d-48a5-9d9e-ad1fae5fab7b"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(vocab_size, 4, input_length=max_len-1))\r\n",
        "model.add(LSTM(32))\r\n",
        "model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 4)              48        \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                4736      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 5,180\n",
            "Trainable params: 5,180\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxJ8OZIABXEq"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \r\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuJYcQVlF9M8"
      },
      "source": [
        "history = model.fit(X, Y, epochs=200, verbose=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxa7HI8fM-ES",
        "outputId": "dfde323f-3aef-422e-f9e3-e61f385d700b"
      },
      "source": [
        "history.history['accuracy'][-1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6363636255264282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg9hx7Q9GLw5"
      },
      "source": [
        "### 모델 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0fWnnbhGJj5"
      },
      "source": [
        "# 모델 검증용 문장을 생성하는 함수\r\n",
        "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\r\n",
        "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\r\n",
        "    sentence = ''\r\n",
        "    for _ in range(n): # n번 반복\r\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\r\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\r\n",
        "        #result = model.predict_classes(encoded, verbose=0)\r\n",
        "        result = np.argmax(model.predict(encoded), axis=-1)\r\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\r\n",
        "        for word, index in t.word_index.items(): \r\n",
        "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\r\n",
        "                break # 해당 단어가 예측 단어이므로 break\r\n",
        "        current_word = current_word + ' ' + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\r\n",
        "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\r\n",
        "        \r\n",
        "    # for문이므로 이 행동을 다시 반복\r\n",
        "    sentence = init_word + sentence\r\n",
        "    return sentence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9TSoBXKaeUV"
      },
      "source": [
        "### 모델변화\r\n",
        "- Embedding Vector 갯수:[2, 4, 6, 8]\r\n",
        "- LSTM 노드 갯수:[24, 32]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVk3NwvNXb4"
      },
      "source": [
        "def execute_model(n_embed, n_lstm):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Embedding(vocab_size, n_embed, input_length=max_len-1))\r\n",
        "    model.add(LSTM(n_lstm))\r\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', \r\n",
        "                  optimizer='adam', metrics=['accuracy'])\r\n",
        "    history = model.fit(X, Y, epochs=200, verbose=0)\r\n",
        "    print(f\"Accuracy: {history.history['accuracy'][-1]:.4f}\")\r\n",
        "\r\n",
        "    print(sentence_generation(model, t, '경마장에', 3))\r\n",
        "    print(sentence_generation(model, t, '그의', 2))\r\n",
        "    print(sentence_generation(model, t, '가는', 5))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SQ62w1FOg2f",
        "outputId": "2ae695e4-e866-483d-ee8d-dfff264f67c4"
      },
      "source": [
        "for n_embed in [2,4,6,8]:\r\n",
        "    for n_lstm in [24,32]:\r\n",
        "        print('===================================')\r\n",
        "        print(f'n_embed={n_embed}, n_lstm={n_lstm}')\r\n",
        "        execute_model(n_embed, n_lstm)\r\n",
        "        print()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================================\n",
            "n_embed=2, n_lstm=24\n",
            "Accuracy: 0.4545\n",
            "경마장에 말이 말이 말이\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 말이 있다\n",
            "\n",
            "===================================\n",
            "n_embed=2, n_lstm=32\n",
            "Accuracy: 0.4545\n",
            "경마장에 말이 말이 말이\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 말이 곱다\n",
            "\n",
            "===================================\n",
            "n_embed=4, n_lstm=24\n",
            "Accuracy: 0.5455\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 있다 있다\n",
            "\n",
            "===================================\n",
            "n_embed=4, n_lstm=32\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 말이 뛰고\n",
            "\n",
            "===================================\n",
            "n_embed=6, n_lstm=24\n",
            "Accuracy: 0.5455\n",
            "경마장에 말이 말이 법이다\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 곱다 곱다\n",
            "\n",
            "===================================\n",
            "n_embed=6, n_lstm=32\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 오는 뛰고 있다\n",
            "\n",
            "===================================\n",
            "n_embed=8, n_lstm=24\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 곱다 곱다\n",
            "\n",
            "===================================\n",
            "n_embed=8, n_lstm=32\n",
            "Accuracy: 0.8182\n",
            "경마장에 말이 고와야 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 고와야 오는 말이 곱다\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}